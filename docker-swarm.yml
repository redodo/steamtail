version: "3.7"

services:

    mq:
        image: rabbitmq
        volumes:
            - mq-data:/var/lib/rabbitmq
        deploy:
            replicas: 1
            placement:
                constraints:
                    - node.role == manager

    redis:
        image: redis
        volumes:
            - redis-data:/data
        deploy:
            replicas: 1
            placement:
                constraints:
                    - node.role == manager

    db:
        image: postgres
        volumes:
            - db-data:/var/lib/postgresql/data
        deploy:
            replicas: 1
            placement:
                constraints:
                    - node.role == manager

    web:
        image: redodo/steamtail
        entrypoint: python manage.py
        command: runserver 0.0.0.0:8814
        ports:
            - "8814:8814"
        depends_on:
            - db
            - mq
        secrets:
            - aws_access_key_id
            - aws_secret_access_key
            - sentry_dsn
        environment:
            DEBUG: 0
            USE_S3_STATICFILES: 1
            AWS_ACCESS_KEY_ID_FILE: /run/secrets/aws_access_key_id
            AWS_SECRET_ACCESS_KEY_FILE: /run/secrets/aws_secret_access_key
            SENTRY_DSN_FILE: /run/secrets/sentry_dsn
        deploy:
            replicas: 1
            restart_policy:
                condition: on-failure
                max_attempts: 3
                window: 30s
                delay: 5s
            placement:
                constraints:
                    - node.role == manager

    # The steamworker only and exclusively processes Steam requests
    # to mitigate and scale rate limits. It does not require database
    # access.
    steamworker:
        image: redodo/steamtail
        entrypoint: celery -A proj worker -Q steamworker -n steamworker@%h
        hostname: {{.Node.Hostname}}
        command: -l info
        depends_on:
            - mq
            - redis
        secrets:
            - sentry_dsn
        environment:
            DEBUG: 0
            SENTRY_DSN_FILE: /run/secrets/sentry_dsn
            DJANGO_SETTINGS_MODULE: proj.settings.steamworker
        deploy:
            restart_policy:
                condition: on-failure
                max_attempts: 3
                window: 30s
                delay: 5s
            mode: global

    # The default worker processes all other tasks.
    worker:
        image: redodo/steamtail
        entrypoint: celery -A proj worker -n worker@%h
        hostname: "{{.Node.Hostname}}:{{.Task.Slot}}"
        command: -l info
        depends_on:
            - db
            - mq
            - redis
        secrets:
            - sentry_dsn
        environment:
            DEBUG: 0
            SENTRY_DSN_FILE: /run/secrets/sentry_dsn
        deploy:
            replicas: 1
            restart_policy:
                condition: on-failure
                max_attempts: 3
                window: 30s
                delay: 5s
            placement:
                constraints:
                    - node.role == manager

    flower:
        image: redodo/steamtail
        entrypoint: celery -A proj flower
        command: --basic_auth=outermosttail:vaporizedsteam
        ports:
            - "5555:5555"
        depends_on:
            - mq
            - redis
        environment:
            DEBUG: 0
        deploy:
            replicas: 1
            restart_policy:
                condition: on-failure
                max_attempts: 3
                window: 30s
                delay: 5s
            placement:
                constraints:
                    - node.role == manager

secrets:
    aws_access_key_id:
        external: true
    aws_secret_access_key:
        external: true
    sentry_dsn:
        external: true

volumes:
    db-data:
    mq-data:
    redis-data:
